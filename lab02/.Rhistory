sum(cond_vals$prob * cond_vals$conditional_variance) + var(cond_vals$conditional_mean)*(11/12)
sum(cond_vals$prob * cond_vals$conditional_variance) + var(cond_vals$conditional_mean)*(11/12)
var(cond_vals$conditional_mean)*(11/12)
var(cond_vals$conditional_mean)*(11/12)/2
sum(cond_vals$prob * cond_vals$conditional_variance) + var(cond_vals$conditional_mean)*(11/12)/2
sum(cond_vals$prob * cond_vals$conditional_variance) + var(cond_vals$conditional_mean)*(11/12)
mean((cond_vals$conditional_mean - uncond_vals$unconditional_mean)^2)
(1/3)*sum((cond_vals$conditional_mean - uncond_vals$unconditional_mean)^2)
(1/4)*sum((cond_vals$conditional_mean - uncond_vals$unconditional_mean)^2)
(1/4)*sum(cond_vals$prob(cond_vals$conditional_mean - uncond_vals$unconditional_mean)^2)
(1/4)*sum(cond_vals$prob*(cond_vals$conditional_mean - uncond_vals$unconditional_mean)^2)
(1/4)*sum((cond_vals$conditional_mean*cond_vals$prob - uncond_vals$unconditional_mean)^2)
sum((cond_vals$prob * cond_vals$conditional_variance)^2) + sum(cond_vals$prob * cond_vals$conditional_variance)^2
sum((cond_vals$prob * cond_vals$conditional_variance)^2) - sum(cond_vals$prob * cond_vals$conditional_variance)^2
sum((cond_vals$prob * cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum((cond_vals$prob * cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * cond_vals$conditional_mean)
sum((cond_vals$prob * cond_vals$conditional_mean)^2)
sum(cond_vals$prob * (cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * cond_vals$conditional_variance)
sum(cond_vals$prob * cond_vals$conditional_variance) + sum(cond_vals$prob * (cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * (cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean^2)
sum(cond_vals$prob * cond_vals$conditional_mean)
sum(cond_vals$prob * (cond_vals$conditional_mean)^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * cond_vals$conditional_mean^2)
sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# Equivalence of variances
uncond_vals$unconditional_variance
# Equivalence of variances
uncond_vals$unconditional_variance*(11/12)
# Again put dataframe into "long" format
cond_vals <- incomes %>%
pivot_longer(everything(), names_to = "department", values_to = "income") %>%
# Group by department to calculate separate statistics by department
group_by(department) %>%
summarise(number = sum(!is.na(income)),
conditional_mean = mean(income, na.rm = TRUE),
conditional_variance = var(income, na.rm = TRUE)*(number - 1)/number,
prob = number/12) %>%
# Finally have to convert to dataframe to later transpose
as.data.frame()
print(t(cond_vals))
sum(cond_vals$prob * cond_vals$conditional_variance)
sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
sum(cond_vals$prob * cond_vals$conditional_variance) + sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# create new dataframe in "long" format
uncond_vals <- incomes %>%
pivot_longer(everything(), names_to = "department", values_to = "income") %>%
# compute mean and variance for each department (excluding na values)
summarise(unconditional_mean = mean(income, na.rm = TRUE),
unconditional_variance = var(income, na.rm = TRUE)*(11/12))
print(uncond_vals)
# Equivalence of variances
uncond_vals$unconditional_variance
sum(cond_vals$prob * cond_vals$conditional_variance) + sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# Equivalence of means
sum(cond_vals$conditional_mean*cond_vals$prob) == uncond_vals$unconditional_mean
# Equivalence of variances
# var(e(x|c)) = e(x^2|c) - e(x | c)^2
term1 <- sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# e(var(x_c))
term2 <- sum(cond_vals$prob * cond_vals$conditional_variance)
uncond_vals$unconditional_variance == term1 + term2
term1 + term2
uncond_vals$unconditional_variance
# Equivalence of means
sum(cond_vals$conditional_mean*cond_vals$prob) == uncond_vals$unconditional_mean
# Equivalence of variances
# var(e(x|c)) = e(x^2|c) - e(x | c)^2
term1 <- sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# e(var(x_c))
term2 <- sum(cond_vals$prob * cond_vals$conditional_variance)
uncond_vals$unconditional_variance
term1 + term2
diff_vars < epsilon
epsilon <- e-5
epsilon <- 1e-5
# Equivalence of means
diff_means <- sum(cond_vals$conditional_mean*cond_vals$prob) - uncond_vals$unconditional_mean
diff_means < epsilon
# Equivalence of variances
# var(e(x|c)) = e(x^2|c) - e(x | c)^2
term1 <- sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# e(var(x_c))
term2 <- sum(cond_vals$prob * cond_vals$conditional_variance)
diff_vars <- uncond_vals$unconditional_variance - (term1 + term2)
diff_vars < epsilon
epsilon <- 1e-5 # Not sure if computer precision will matter here but I suppose it's good to be safe
# Equivalence of means
diff_means <- sum(cond_vals$conditional_mean*cond_vals$prob) - uncond_vals$unconditional_mean
diff_means < epsilon
# Equivalence of variances
# var(e(x|c)) = e(x^2|c) - e(x | c)^2
term1 <- sum(cond_vals$prob * cond_vals$conditional_mean^2) - sum(cond_vals$prob * cond_vals$conditional_mean)^2
# e(var(x_c))
term2 <- sum(cond_vals$prob * cond_vals$conditional_variance)
diff_vars <- uncond_vals$unconditional_variance - (term1 + term2)
diff_vars < epsilon
mean(samples$mean) == mean(exams)
mean(samples$sample_var) == var(exams)
data(iris)
iris %>% group_by(Species) %>%
summarise(prop = n()/nrow(iris))
iris %>% group_by(Species) %>%
summarise(prop = n()/nrow(iris)) %>%
ggplot(aes(x = Species)) +
geom_bar(stat = "identity")
iris %>% group_by(Species) %>%
summarise(prop = n()/nrow(iris)) %>%
ggplot(aes(x = Species, y = prop)) +
geom_bar(stat = "identity")
ggplot(iris, aes(x = Species, y = prop, group = 1)) +
geom_bar()
ggplot(iris, aes(x = Species, y = ..prop.., group = 1)) +
geom_bar()
ggplot(iris, aes(x = Species, y = ..prop..)) +
geom_bar()
ggplot(iris, aes(x = Species, y = ..prop.., group = 1)) +
geom_bar()
ggplot(iris, aes(x = Species, y = ..prop..)) +
geom_bar()
ggplot(iris, aes(x = Species, y = ..prop.., group = 1)) +
geom_bar()
emails <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise1.csv")
emails %>% group_by(Email) %>%
summarise(n = n()) %>%
arrange(desc(n))
emails %>% group_by(Email) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(10)
emails %>% group_by(Email) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(15)
data <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise2.csv")
data <- data %>% rename(area = Program.Area,
site_visit = Had.a.site.visit..1.Yes..0.No.,
rating = Helpfulness.of.site.visit..1...not.at.all.helpful..7...extremely.helpful.)
data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
View(data)
data <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise2.csv")
data <- data %>% rename(area = Program.Area,
site_visit = Had.a.site.visit..1.Yes..0.No.,
rating = Helpfulness.of.site.visit..1...not.at.all.helpful..7...extremely.helpful.) %>%
select(area, site_visit, rating, Response) %>%
filter(!is.na(Response))
data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
View(data)
data <- data %>% rename(area = Program.Area,
site_visit = Had.a.site.visit..1.Yes..0.No.,
rating = Helpfulness.of.site.visit..1...not.at.all.helpful..7...extremely.helpful.) %>%
select(area, site_visit, rating, Response) %>%
filter(!is.na(Response), Response != "")
data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
data <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise2.csv")
data <- data %>% rename(area = Program.Area,
site_visit = Had.a.site.visit..1.Yes..0.No.,
rating = Helpfulness.of.site.visit..1...not.at.all.helpful..7...extremely.helpful.) %>%
select(area, site_visit, rating, Response) %>%
filter(!is.na(Response), Response != "")
data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
table
library(clipr)
write_clip(table)
overall <- data %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE))
write_clip(overall)
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
round(2)
write_clip(table)
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
round(2)
data <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise2.csv")
data <- data %>% rename(area = Program.Area,
site_visit = Had.a.site.visit..1.Yes..0.No.,
rating = Helpfulness.of.site.visit..1...not.at.all.helpful..7...extremely.helpful.) %>%
select(area, site_visit, rating, Response) %>%
filter(!is.na(Response), Response != "")
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
round(2)
write_clip(table)
View(table)
table
round(table, 2)
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
mutate(across(-area, round(., 2)))
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
mutate(across(-area), round(., 2))
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
mutate(across(-area, ~ round(., 2)))
write_clip(table)
View(table)
table <- data %>% group_by(area) %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
mutate(across(-area, ~ round(., 3)))
write_clip(table)
overall <- data %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
mutate(across(-area, ~ round(., 3)))
overall <- data %>%
summarise(number_grantees = n(),
prop_site_visit = mean(site_visit, na.rm = TRUE),
avg_rating = mean(rating, na.rm = TRUE)) %>%
round(3)
write_clip(overall)
emails <- read.csv("/Users/hajohns/Desktop/cep_interview/exercise1.csv")
emails %>% group_by(Email) %>%
summarise(n = n()) %>%
arrange(desc(n)) %>%
head(15)
library(tidyverse)
likelihood_function <- function(p = .5, n = 20){
x <- 1:n
result <- map(x, function(i) binom(n, i)*p^i * (1-p)^(n-i))
return(result)
}
ggplot(1:2) +
stat_function(likelihood_function)
ggplot(data = data.frame(x = 0:1)) +
stat_function(likelihood_function)
ggplot(data = data.frame(x = 0:1)) +
stat_function(fun = likelihood_function)
?binom
binomial
?binomial
likelihood_function <- function(p = .5, n = 20){
x <- 1:n
result <- map(x, function(i) choose(n, i)*p^i * (1-p)^(n-i))
return(result)
}
ggplot(data = data.frame(x = 0:1)) +
stat_function(fun = likelihood_function)
ggplot(data = data.frame(x = 0:1)) +
geom_point() +
stat_function(fun = likelihood_function)
ggplot(data = data.frame(x = 0:1)) +
stat_function(fun = likelihood_function)
values <- likelihood_function()
View(values)
values <- likelihood_function() %>% unlist()
likelihood_function <- function(i = 20, n = 20, p = seq(0, 1, by = .01)){
result <- map(p, function(prob) choose(n, i)*prob^i * (1-prob)^(n-i))
return(result)
}
values <- likelihood_function()
View(values)
likelihood_function <- function(i = 20, n = 20, p = seq(0, 1, by = .01)){
result <- map(p, function(prob) choose(n, i)*prob^i * (1-prob)^(n-i))
return(unlist(result))
}
values <- likelihood_function()
values
data = data.frame(p = seq(0, 1, by = .01),
l = likelihood_function())
ggplot(data, aes(x = p, y = l)) +
geom_line()
.5^(20)
pchisq(lrt, df = 1)
(lambda <- .5^(20))
lrt <- -2*log(lambda)
pchisq(lrt, df = 1)
pchisq(lrt, df = 1, lower.tail = FALSE)
(lambda <- .5^(20))
lrt <- -2*log(lambda)
pchisq(lrt, df = 1, lower.tail = FALSE)
zstar = dnorm(.025)
zstar = pnorm(.025)
zstar <- qnorm(.025)
se <- sqrt(1*1)
zstar <- qnorm(.025)
pi_hat <- 1
se <- sqrt(pi_hat * (1 - pi_hat))
upper_bound <- zstar*se + pi_hat
zstar*se + pi_hat
zstar <- qnorm(.025)
pi_hat <- 1
se <- sqrt(pi_hat * (1 - pi_hat))
upper_bound <- zstar*se + pi_hat
lower_bound <- zstar*se - pi_hat
upper_bound <- pi_hat + zstar*se
lower_bound <- pi_hat - zstar*se
zstar <- qnorm(.025)
pi_hat <- 1
se <- sqrt(pi_hat * (1 - pi_hat)/20)
upper_bound <- pi_hat + zstar*se
lower_bound <- pi_hat - zstar*se
zstar <- qnorm(.025)
pi_hat <- 1
se <- sqrt(pi_hat * (1 - pi_hat)/20)
(upper_bound <- pi_hat + zstar*se)
(lower_bound <- pi_hat - zstar*se)
ggplot(data = data, aes(x = p, y = l, )) + geom_point()
ggplot(mpg, aes(x = cty, y = hwy)) +
facet_wrap(class ~ fl) +
geom_point()
data <- read.csv("/Users/hajohns/Desktop/stat_306/CollegeScorecard_Raw_Data_08032021/Most-Recent-Cohorts-All-Data-Elements.csv")
View(data)
data <- data %>% select(UNITED, INSTNM, CITY, STABBR, ZIP, SCH_DEG,
MAIN, SATVRMID,
SATMTMID, SAT_AVG, UGDS,
PCIP27, PCIP46, NPT4_PUB, NPT4_PRIV,
PCTPELL, MEDIAN_HH_INC)
data <- data %>% select(UNITID, INSTNM, CITY, STABBR, ZIP, SCH_DEG,
MAIN, SATVRMID,
SATMTMID, SAT_AVG, UGDS,
PCIP27, PCIP46, NPT4_PUB, NPT4_PRIV,
PCTPELL, MEDIAN_HH_INC)
write.csv(data, "/Users/hajohns/Desktop/stat_306/stat-computing-lab/lab04")
write.csv(data, "/Users/hajohns/Desktop/stat_306/stat-computing-lab/lab04/college_scorecard.csv")
pi1 <- 0.00159
pi2 <- 0.0191
pi1 - pi2
pi1/pi2
(pi1/(1-pi1))/(pi2/(1-pi2))
(pi1/(1-pi1))
(pi2/(1-pi2))
pi1 <- 0.393
pi2 <- 0.888
pi1 - pi2
pi1/pi2
(pi1/(1-pi1))/(pi2/(1-pi2))
pi1 <- 0.00159
pi2 <- 0.0191
pi1 - pi2
pi1/pi2
(pi1/(1-pi1))/(pi2/(1-pi2))
pi1 <- 0.00159
pi2 <- 0.0191
pi1 - pi2
pi1/pi2
(pi1/(1-pi1))/(pi2/(1-pi2))
admissions <- data.frame(department = c("A", "B", "C", "D", "E", "F"),
male_admited = c(512, 353, 120, 138, 53, 22),
male_rejected = c(313, 207, 205, 279, 138, 351),
female_admitted = c(89, 17, 202, 131, 94, 24),
female_rejected = c(19, 8, 391, 244, 299, 317))
admissions$odds_ratio_conditional <- admissions$male_admited * admissions$female_rejected /
(admissions$male_rejected * admissions$female_admitted)
View(admissions)
total <- rowSums(admissions)
total <- rowSums(admissions[, -department])
total <- rowSums(admissions[, -c("department")])
total <- rowSums(admissions[, -1])
total <- colSums(admissions[, -1])
total
admissions <- data.frame(department = c("A", "B", "C", "D", "E", "F"),
male_admited = c(512, 353, 120, 138, 53, 22),
male_rejected = c(313, 207, 205, 279, 138, 351),
female_admitted = c(89, 17, 202, 131, 94, 24),
female_rejected = c(19, 8, 391, 244, 299, 317))
total <- colSums(admissions[, -1])
admissions$odds_ratio_conditional <- admissions$male_admited * admissions$female_rejected /
(admissions$male_rejected * admissions$female_admitted)
View(admissions)
odds_ratio_marginal <- total[1] * total[4] / (total[2] * total[3])
admissions[ , c("department")]
odds_ratio_marginal
odds_ratio_marginal[1]
unname(odds_ratio_marginal)
gss <- data.frame(premarital_sex = c("always_wrong", "almost_always", "sometimes", "not_wrong"),
always_wrong = c(300, 78, 107, 234),
almost_always = c(4, 15, 16, 32),
sometimes = c(4, 3, 46, 35),
not_wrong = c(17, 14, 54, 336))
View(gss)
gss
rownames(gss) <- c("always_wrong", "almost_always", "sometimes", "not_wrong")
gss
gss <- data.frame(always_wrong = c(300, 78, 107, 234),
almost_always = c(4, 15, 16, 32),
sometimes = c(4, 3, 46, 35),
not_wrong = c(17, 14, 54, 336))
rownames(gss) <- c("always_wrong", "almost_always", "sometimes", "not_wrong")
gss
# conconcordance
sum <- 0
for(i in 1:3){
for (j in 1:3){
value <- gss[i, j]
inner_sum <- 0
for(k in 1:(i-1)){
for(l in (j+1):4){
inner_sum <- inner_sum + gss[k, l]
}
}
sum <- sum + value*inner_sum
}
}
# conconcordance
sum <- 0
for(i in 1:3){
for (j in 1:3){
value <- gss[i, j]
inner_sum <- 0
for(k in 1:(i-1)){
for(l in (j+1):4){
inner_sum <- inner_sum + gss[k, l]
}
}
sum <- sum + value*inner_sum
}
}
# concordance
sum <- 0
for(i in 1:3){
for (j in 1:3){
value <- gss[i, j]
inner_sum <- 0
for(k in (i+1):4){
for(l in (j+1):4){
inner_sum <- inner_sum + gss[k, l]
}
}
sum <- sum + value*inner_sum
}
}
# concordance
discordance <- 0
for(i in 1:3){
for (j in 2:4){
value <- gss[i, j]
inner_sum <- 0
for(k in (i+1):4){
for(l in 1:(j-1)){
inner_sum <- inner_sum + gss[k, l]
}
}
discordance <- discordance + value*inner_sum
}
}
concordance
discordance
concordance
# concordance
concordance <- 0
for(i in 1:3){
for (j in 1:3){
value <- gss[i, j]
inner_sum <- 0
for(k in (i+1):4){
for(l in (j+1):4){
inner_sum <- inner_sum + gss[k, l]
}
}
concordance <- concordance + value*inner_sum
}
}
concordance
discordance
gamma <- (concordance - discordance)/(concordance + discordance)
gamma
"2022-02-04" - ddays(60)
library(lubridate)
"2022-02-04" - ddays(60)
mdy("2022-02-04") - ddays(60)
ddays(60)
mdy("2022-02-04") - "60 days"
mdy("2022-02-04") - unit(60, units = "days")
mdy("2022-02-04") - days(60)
mdy(2022-02-04")
mdy("2022-02-04")
mdy("2022-02-04")
library(lubridate)
mdy("2022-02-04")
dmy("2022-02-04")
as.Date("2022-02-04")
mdy("2022-02-04")
as.Date("2022-02-04")
as.Date("2022-02-04") - days(60)
Sys.Date
Sys.Date()
